# AGI Ventures Canada Hackathon 3.0 - Complete Judging Criteria

## Overview
**Theme**: Build to Convert  
**Objective**: Create products people actually want and will pay for  
**Duration**: Sept 6-7, 2025  
**Location**: Invest Ottawa

## Two Tracks

### 1. Technical Track
- Coding experience required
- Focus on technical innovation and implementation

### 2. General Track  
- Vibe coding encouraged (using AI to code)
- Open to non-technical participants
- Focus on business viability and creativity

## Complete Award Categories & Evaluation Criteria

### 1. Best Use of Solace Agent Mesh (Technical Track)
**Evaluation Criteria**:
- Meaningful integration (not just a mention)
- Agents automate or enhance real workflows
- Technical creativity + real-world potential
- Effective use of agent communication
- Scalability of the solution

**Submission Requirements**:
- Working demo with Solace Agent Mesh
- Documentation of integration
- Clear use case explanation

### 2. Most Revenue (General Track)
**Evaluation Criteria**:
- Total revenue generated between Sept 6 @ 9AM - Sept 12 @ 5PM
- Proof of transactions (Stripe, PayPal, Shopify, Gumroad, Paddle, etc.)
- Both B2B & B2C sales count
- Pre-sales allowed if processed on platform
- NO cash transactions accepted

**Submission Requirements**:
- Transaction screenshots with timestamps
- Payment platform dashboard access
- Customer testimonials (bonus)

### 3. Fastest to First Sales (General Track)
**Evaluation Criteria**:
- Speed to first real paying customer
- B2C: First 5 sales required
- B2B: First sale counts
- Must be external customers (not team members)
- Timestamped proof required

**Submission Requirements**:
- Transaction proof with exact timestamp
- Customer information (anonymized okay)
- Sales process documentation

### 4. Most People on Waitlist (General Track)
**Evaluation Criteria**:
- Total number of signups
- Quality of landing page
- Conversion rate
- Geographic diversity (bonus)
- Engagement metrics

**Submission Requirements**:
- Form/email tool with visible count
- Landing page URL
- Analytics dashboard access

### 5. Most Unique GTM (Go-To-Market) (General Track)
**Evaluation Criteria**:
- Creativity and originality
- Memorability of approach
- Alignment with product
- Community-first strategies
- Stunt marketing effectiveness

**Submission Requirements**:
- Documentation of GTM strategy
- Evidence of execution
- Metrics and results

### 6. Best Outbound Automation (General Track)
**Evaluation Criteria**:
- Automation sophistication
- Efficiency gains demonstrated
- Creative use of tools (Zapier, MCP, custom scripts)
- Scalability of solution
- Real-world applicability

**Submission Requirements**:
- Automation workflow documentation
- Demo of system in action
- Metrics on efficiency gains

### 7. Best AI for Environmental Impact (General Track)
**Evaluation Criteria**:
- Clear environmental benefit
- Measurable impact potential
- Scalability of solution
- Innovation in approach
- Feasibility of implementation

**Submission Requirements**:
- Impact measurement methodology
- Projected environmental benefits
- Scientific backing (if applicable)

### 8. Best Launch Video (General Track)
**Evaluation Criteria**:
- Clear value proposition
- Creativity and storytelling
- Production quality (sound, visuals, flow)
- Engagement potential
- Call-to-action effectiveness

**Submission Requirements**:
- Video file (2-3 minutes ideal)
- YouTube/Vimeo link
- View/engagement metrics

### 9. Most $$ Lost (Biggest Burner) (General Track)
**Evaluation Criteria**:
- Real spend/loss documentation
- Legal and ethical approach
- Learning value from failure
- Humor in storytelling
- Transparency in sharing

**Submission Requirements**:
- Expense documentation
- Story of what went wrong
- Lessons learned document

### 10. Hype Machine - LinkedIn & X (General Track)
**Evaluation Criteria**:
- Total engagement (likes, shares, comments)
- Reach and impressions
- Content creativity
- Consistency of posting
- Community building

**Requirements**:
- Must tag @AgiVentures on X/LinkedIn
- Use hashtags: #AGIV #AGIVenturesCanada #BuildToConvert
- No sharing of hackathon promo codes
- Original content only

**Submission Requirements**:
- Links to all posts
- Analytics screenshots
- Engagement metrics summary

### 11. Best UI (General Track)
**Evaluation Criteria**:
- Aesthetic appeal
- UX clarity and intuitive flow
- Creative design elements
- Consistency across application
- Mobile responsiveness

**Submission Requirements**:
- Live demo or screenshots
- Design system documentation
- User flow diagrams

### 12. Audience Favorite (General Track)
**Evaluation Criteria**:
- Community voting (Sunday survey)
- Overall appeal
- Presentation quality
- Team enthusiasm
- Problem-solution fit

**Submission Requirements**:
- Final presentation
- Live demo
- Team introduction

### 13. Funniest Hack (General Track)
**Evaluation Criteria**:
- Originality and humor
- Technical or conceptual wit
- Functionality (must actually work)
- Entertainment value
- Meme potential

**Submission Requirements**:
- Working demo
- Explanation of the joke/concept
- User reactions (bonus)

### 14. Hackathon Spirit (General Track)
**Evaluation Criteria**:
- Collaboration with other teams
- Knowledge sharing
- Helping others debug/solve problems
- Positive energy contribution
- Community building efforts

**Submission Requirements**:
- Peer nominations
- Documentation of help provided
- Community testimonials

### 15. Best Costume (General Track)
**Evaluation Criteria**:
- Creativity and execution
- Alignment with project theme
- Effort level
- Team coordination (bonus)
- Audience reaction

**Submission Requirements**:
- Photos throughout event
- Costume explanation
- Team participation

## AI Evaluation System Requirements

### Core Evaluation Dimensions

#### 1. Technical Innovation (25%)
- Code quality and architecture
- Use of cutting-edge technologies
- Scalability considerations
- Security implementation
- Performance optimization

#### 2. Business Viability (25%)
- Market size and opportunity
- Revenue model clarity
- Customer validation
- Competitive advantage
- Growth potential

#### 3. Execution Quality (20%)
- Completeness of implementation
- Polish and attention to detail
- Bug-free operation
- Documentation quality
- Deployment success

#### 4. Presentation & Pitch (15%)
- Clarity of communication
- Storytelling effectiveness
- Demo quality
- Team dynamics
- Q&A handling

#### 5. Innovation & Creativity (15%)
- Uniqueness of approach
- Problem-solving creativity
- Design innovation
- User experience innovation
- Technical creativity

### Scoring Methodology

#### Numerical Scoring
- Each criterion: 0-100 points
- Weighted average for final score
- Bonus points for special achievements
- Penalty for incomplete submissions

#### Qualitative Assessment
- Strengths identification
- Weaknesses analysis
- Improvement suggestions
- Market fit evaluation
- Technical debt assessment

### Submission Requirements

#### Mandatory Deliverables
1. **Project Description** (500 words max)
2. **Live Demo URL** or video
3. **Source Code Repository** (if technical track)
4. **Pitch Deck** (PDF, 10 slides max)
5. **Team Information**

#### Optional Deliverables
1. Business plan
2. Financial projections
3. User testimonials
4. Technical architecture diagram
5. Marketing materials

### Timeline Checkpoints

#### Saturday (Day 1)
- 10:30 AM - Building begins
- 12:00 PM - First progress check
- 3:00 PM - Mid-day evaluation
- 6:00 PM - Evening progress
- 9:45 PM - End of day status

#### Sunday (Day 2)
- 9:00 AM - Final submissions due
- 9:30 AM - Judging begins
- 10:00 AM - Finalists announced
- 10:15 AM - Final pitches
- 11:45 AM - Winners announced

### Special Considerations

#### Vibe Coding Projects
- Evaluated on outcome, not code quality
- Focus on business metrics
- User experience weighted higher
- Creative use of AI tools

#### Technical Projects
- Code review emphasis
- Architecture evaluation
- Performance benchmarks
- Security assessment

### Disqualification Criteria
- Late submission
- Plagiarism or copying
- Unethical practices
- Team member violations
- False revenue claims
- Use of pre-existing code without declaration

### Bonus Point Opportunities
- Open source commitment
- Environmental consideration
- Accessibility features
- Community contribution
- Educational value
- Social impact

## AI Agent Evaluation Framework

### Document Processing Pipeline
1. **Intake**: Accept multiple file formats
2. **Extraction**: Parse content and metadata
3. **Analysis**: Multi-agent evaluation
4. **Scoring**: Calculate weighted scores
5. **Feedback**: Generate actionable insights

### Agent Specializations
- **Technical Agent**: Code quality, architecture, innovation
- **Business Agent**: Market fit, revenue potential, scalability
- **UX Agent**: Design, usability, user flow
- **Presentation Agent**: Pitch quality, storytelling, clarity
- **Compliance Agent**: Rule adherence, completeness

### Real-time Tracking
- Submission timestamps
- Score evolution
- Comparative analysis
- Progress indicators
- Achievement unlocking

---

*This document serves as the comprehensive guide for both human judges and the AI evaluation system for AGI Ventures Canada Hackathon 3.0*